#!/usr/bin/env python3
"""
Florence-2 OCRä¸æ‰‹å†™è¯†åˆ«ä¸“ç”¨è„šæœ¬
ä¸“é—¨ä¼˜åŒ–ç”¨äºæ–‡æ¡£OCRã€æ‰‹å†™è¯†åˆ«ã€è¡¨æ ¼æå–ç­‰ä»»åŠ¡
"""

import torch
from PIL import Image
from transformers import AutoProcessor, AutoModelForCausalLM
import numpy as np
from pathlib import Path
import json
import re
from typing import Dict, List, Tuple, Optional
import pandas as pd

class Florence2OCR:
    """Florence-2 OCRä¸“ç”¨å¤„ç†å™¨"""
    
    def __init__(self, model_id="microsoft/Florence-2-large"):
        """
        åˆå§‹åŒ–OCRæ¨¡å‹
        
        Args:
            model_id: æ¨¡å‹ID
                - microsoft/Florence-2-base: è½»é‡ç‰ˆ
                - microsoft/Florence-2-large: é«˜ç²¾åº¦ç‰ˆ
        """
        print(f"ğŸ“š æ­£åœ¨åŠ è½½ Florence-2 OCR æ¨¡å‹: {model_id}")
        
        # åŠ è½½æ¨¡å‹
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        dtype = torch.float16 if torch.cuda.is_available() else torch.float32
        
        self.model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=dtype,
            trust_remote_code=True
        ).to(self.device)
        
        self.processor = AutoProcessor.from_pretrained(
            model_id, 
            trust_remote_code=True
        )
        
        self.model.eval()
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {self.device})")
    
    def ocr_image(self, image_path: str, task_type: str = "ocr") -> Dict:
        """
        æ‰§è¡ŒOCRè¯†åˆ«
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            task_type: ä»»åŠ¡ç±»å‹
                - "ocr": åŸºç¡€OCR
                - "ocr_with_region": å¸¦åŒºåŸŸä¿¡æ¯çš„OCR
        
        Returns:
            OCRç»“æœå­—å…¸
        """
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        # é€‰æ‹©ä»»åŠ¡æç¤ºè¯
        if task_type == "ocr_with_region":
            prompt = "<OCR_WITH_REGION>"
        else:
            prompt = "<OCR>"
        
        # å¤„ç†å›¾åƒ
        inputs = self.processor(
            text=prompt,
            images=image,
            return_tensors="pt"
        ).to(self.device)
        
        # ç”Ÿæˆæ–‡æœ¬
        with torch.no_grad():
            generated_ids = self.model.generate(
                input_ids=inputs["input_ids"],
                pixel_values=inputs["pixel_values"],
                max_new_tokens=2048,  # å¢åŠ é•¿åº¦ä»¥å¤„ç†é•¿æ–‡æ¡£
                do_sample=False,
                num_beams=3,
                early_stopping=False  # ä¸è¦è¿‡æ—©åœæ­¢ï¼Œç¡®ä¿å®Œæ•´è¯†åˆ«
            )
        
        # è§£ç ç»“æœ
        generated_text = self.processor.batch_decode(
            generated_ids,
            skip_special_tokens=False
        )[0]
        
        # è§£æç»“æœ
        parsed_answer = self.processor.post_process_generation(
            generated_text,
            task=prompt,
            image_size=(image.width, image.height)
        )
        
        return {
            'text': self._extract_text(parsed_answer, task_type),
            'raw_output': generated_text,
            'parsed_output': parsed_answer,
            'image_size': (image.width, image.height)
        }
    
    def _extract_text(self, parsed_output: Dict, task_type: str) -> str:
        """ä»è§£æè¾“å‡ºä¸­æå–çº¯æ–‡æœ¬"""
        if isinstance(parsed_output, dict):
            if task_type == "ocr" and 'OCR' in parsed_output:
                return parsed_output['OCR']
            elif task_type == "ocr_with_region" and 'OCR_WITH_REGION' in parsed_output:
                # å¤„ç†å¸¦åŒºåŸŸçš„OCRç»“æœ
                regions = parsed_output['OCR_WITH_REGION']
                if 'quad_boxes' in regions and 'labels' in regions:
                    # æŒ‰ä½ç½®æ’åºæ–‡æœ¬
                    texts = regions['labels']
                    boxes = regions['quad_boxes']
                    
                    # ç®€å•çš„ä»ä¸Šåˆ°ä¸‹ï¼Œä»å·¦åˆ°å³æ’åº
                    sorted_pairs = sorted(
                        zip(boxes, texts),
                        key=lambda x: (min(x[0][1], x[0][3]), min(x[0][0], x[0][2]))
                    )
                    
                    return '\n'.join([text for _, text in sorted_pairs])
                return str(regions)
        return str(parsed_output)
    
    def extract_table(self, image_path: str) -> pd.DataFrame:
        """
        ä»å›¾åƒä¸­æå–è¡¨æ ¼
        
        Args:
            image_path: åŒ…å«è¡¨æ ¼çš„å›¾åƒè·¯å¾„
        
        Returns:
            æå–çš„è¡¨æ ¼æ•°æ® (DataFrame)
        """
        print(f"ğŸ“Š æå–è¡¨æ ¼: {image_path}")
        
        # ä½¿ç”¨å¸¦åŒºåŸŸçš„OCR
        result = self.ocr_image(image_path, "ocr_with_region")
        text = result['text']
        
        # å°è¯•è§£æè¡¨æ ¼ç»“æ„
        lines = text.split('\n')
        
        # ç®€å•çš„è¡¨æ ¼è§£æé€»è¾‘
        # è¿™é‡Œå‡è®¾è¡¨æ ¼æ˜¯ç”¨ç©ºæ ¼æˆ–åˆ¶è¡¨ç¬¦åˆ†éš”çš„
        table_data = []
        for line in lines:
            if line.strip():
                # å°è¯•ç”¨å¤šç§åˆ†éš”ç¬¦åˆ†å‰²
                cells = re.split(r'\s{2,}|\t|ï½œ|\|', line.strip())
                cells = [cell.strip() for cell in cells if cell.strip()]
                if cells:
                    table_data.append(cells)
        
        # åˆ›å»ºDataFrame
        if table_data:
            # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´
            df = pd.DataFrame(table_data[1:], columns=table_data[0])
            return df
        else:
            return pd.DataFrame()
    
    def process_handwritten(self, image_path: str) -> Dict:
        """
        ä¸“é—¨å¤„ç†æ‰‹å†™æ–‡æ¡£
        
        Args:
            image_path: æ‰‹å†™æ–‡æ¡£å›¾åƒè·¯å¾„
        
        Returns:
            è¯†åˆ«ç»“æœ
        """
        print(f"âœï¸ å¤„ç†æ‰‹å†™æ–‡æ¡£: {image_path}")
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        results = {}
        
        # 1. æ‰§è¡ŒåŸºç¡€OCR
        print("  æ‰§è¡ŒOCRè¯†åˆ«...")
        ocr_result = self.ocr_image(image_path, "ocr")
        results['ocr_text'] = ocr_result['text']
        
        # 2. æ‰§è¡Œå¸¦åŒºåŸŸçš„OCRï¼ˆè·å–å¸ƒå±€ä¿¡æ¯ï¼‰
        print("  åˆ†ææ–‡æ¡£å¸ƒå±€...")
        region_result = self.ocr_image(image_path, "ocr_with_region")
        results['structured_text'] = region_result['text']
        
        # 3. ç”Ÿæˆæ–‡æ¡£æè¿°
        print("  ç”Ÿæˆæ–‡æ¡£æè¿°...")
        caption_result = self._get_caption(image)
        results['description'] = caption_result
        
        # 4. åå¤„ç†ï¼šæ¸…ç†å’Œæ ¼å¼åŒ–æ–‡æœ¬
        results['cleaned_text'] = self._clean_handwritten_text(results['ocr_text'])
        
        return results
    
    def _get_caption(self, image: Image.Image) -> str:
        """è·å–å›¾åƒæè¿°"""
        prompt = "<DETAILED_CAPTION>"
        
        inputs = self.processor(
            text=prompt,
            images=image,
            return_tensors="pt"
        ).to(self.device)
        
        with torch.no_grad():
            generated_ids = self.model.generate(
                input_ids=inputs["input_ids"],
                pixel_values=inputs["pixel_values"],
                max_new_tokens=256,
                do_sample=False,
                num_beams=3
            )
        
        generated_text = self.processor.batch_decode(
            generated_ids,
            skip_special_tokens=False
        )[0]
        
        parsed = self.processor.post_process_generation(
            generated_text,
            task=prompt,
            image_size=(image.width, image.height)
        )
        
        if isinstance(parsed, dict) and 'DETAILED_CAPTION' in parsed:
            return parsed['DETAILED_CAPTION']
        return str(parsed)
    
    def _clean_handwritten_text(self, text: str) -> str:
        """æ¸…ç†æ‰‹å†™è¯†åˆ«æ–‡æœ¬"""
        if not text:
            return ""
        
        # ä¿®å¤å¸¸è§çš„æ‰‹å†™è¯†åˆ«é”™è¯¯
        cleaned = text
        
        # ä¿®å¤æ ‡ç‚¹ç¬¦å·é—´è·
        cleaned = re.sub(r'\s+([,.\!?;:])', r'\1', cleaned)
        cleaned = re.sub(r'([,.\!?;:])\s*', r'\1 ', cleaned)
        
        # ä¿®å¤å¤šä½™çš„ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # ä¿®å¤æ®µè½
        cleaned = re.sub(r'\n\s*\n', '\n\n', cleaned)
        
        return cleaned.strip()
    
    def batch_process(self, folder_path: str, output_dir: str = None):
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒ
        
        Args:
            folder_path: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        """
        folder = Path(folder_path)
        if not folder.exists():
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir is None:
            output_path = Path("/workspace/output/florence2")
        else:
            output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True, parents=True)
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp']
        image_files = []
        for ext in image_extensions:
            image_files.extend(folder.glob(f"*{ext}"))
            image_files.extend(folder.glob(f"*{ext.upper()}"))
        
        if not image_files:
            print(f"âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return
        
        print(f"ğŸ“‚ æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        # æ‰¹é‡å¤„ç†
        all_results = []
        
        for i, image_file in enumerate(image_files, 1):
            print(f"\n[{i}/{len(image_files)}] å¤„ç†: {image_file.name}")
            
            try:
                # OCRè¯†åˆ«
                result = self.ocr_image(str(image_file))
                
                # ä¿å­˜æ–‡æœ¬ç»“æœ
                text_file = output_path / f"{image_file.stem}.txt"
                with open(text_file, 'w', encoding='utf-8') as f:
                    f.write(result['text'])
                
                # è®°å½•ç»“æœ
                all_results.append({
                    'file': str(image_file),
                    'output': str(text_file),
                    'text_length': len(result['text']),
                    'status': 'success'
                })
                
                print(f"  âœ… å·²ä¿å­˜åˆ°: {text_file.name}")
                print(f"  è¯†åˆ«å­—ç¬¦æ•°: {len(result['text'])}")
                
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
                all_results.append({
                    'file': str(image_file),
                    'status': 'failed',
                    'error': str(e)
                })
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_file = output_path / "summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“Š å¤„ç†å®Œæˆï¼")
        print(f"  æˆåŠŸ: {sum(1 for r in all_results if r['status'] == 'success')}")
        print(f"  å¤±è´¥: {sum(1 for r in all_results if r['status'] == 'failed')}")
        print(f"  ç»“æœä¿å­˜åœ¨: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Florence-2 OCRå·¥å…·')
    parser.add_argument('input', help='è¾“å…¥å›¾åƒæˆ–æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model', default='microsoft/Florence-2-large',
                       choices=['microsoft/Florence-2-base', 'microsoft/Florence-2-large'],
                       help='æ¨¡å‹ç‰ˆæœ¬')
    parser.add_argument('--region', action='store_true', 
                       help='ä½¿ç”¨å¸¦åŒºåŸŸä¿¡æ¯çš„OCR')
    parser.add_argument('--table', action='store_true',
                       help='æå–è¡¨æ ¼')
    parser.add_argument('--handwritten', action='store_true',
                       help='æ‰‹å†™æ–‡æ¡£æ¨¡å¼')
    parser.add_argument('--batch', action='store_true',
                       help='æ‰¹é‡å¤„ç†æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºOCRå¤„ç†å™¨
    ocr = Florence2OCR(model_id=args.model)
    
    # åˆ¤æ–­è¾“å…¥ç±»å‹
    input_path = Path(args.input)
    
    if input_path.is_dir() or args.batch:
        # æ‰¹é‡å¤„ç†
        ocr.batch_process(args.input, args.output)
    elif input_path.is_file():
        # å•æ–‡ä»¶å¤„ç†
        if args.table:
            # æå–è¡¨æ ¼
            df = ocr.extract_table(args.input)
            if not df.empty:
                print("\næå–çš„è¡¨æ ¼:")
                print(df)
                
                # ä¿å­˜CSV
                output_dir = Path("/workspace/output/florence2")
                output_dir.mkdir(exist_ok=True, parents=True)
                output_file = output_dir / f"{input_path.stem}_table.csv"
                df.to_csv(output_file, index=False, encoding='utf-8')
                print(f"\nè¡¨æ ¼å·²ä¿å­˜åˆ°: {output_file}")
            else:
                print("æœªèƒ½æå–åˆ°è¡¨æ ¼æ•°æ®")
                
        elif args.handwritten:
            # æ‰‹å†™æ–‡æ¡£æ¨¡å¼
            results = ocr.process_handwritten(args.input)
            
            print("\nğŸ“ æ‰‹å†™è¯†åˆ«ç»“æœ:")
            print("-" * 50)
            print(results['cleaned_text'])
            print("-" * 50)
            print(f"\næ–‡æ¡£æè¿°: {results['description']}")
            
            # ä¿å­˜ç»“æœ
            output_dir = Path("/workspace/output/florence2")
            output_dir.mkdir(exist_ok=True, parents=True)
            output_file = output_dir / f"{input_path.stem}_handwritten.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"\nå®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
        else:
            # æ™®é€šOCR
            task_type = "ocr_with_region" if args.region else "ocr"
            result = ocr.ocr_image(args.input, task_type)
            
            print("\nğŸ“– OCRè¯†åˆ«ç»“æœ:")
            print("=" * 60)
            print(result['text'])
            print("=" * 60)
            
            # ä¿å­˜ç»“æœ
            output_dir = Path("/workspace/output/florence2")
            output_dir.mkdir(exist_ok=True, parents=True)
            output_file = output_dir / f"{input_path.stem}_ocr.txt"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(result['text'])
            print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    else:
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) == 1:
        # äº¤äº’å¼ç•Œé¢
        print("ğŸ”¤ Florence-2 OCR å·¥å…·")
        print("=" * 60)
        print("ä¸“é—¨ä¼˜åŒ–ç”¨äº:")
        print("  â€¢ ğŸ“– æ–‡æ¡£OCR - è¯†åˆ«å°åˆ·å’Œæ‰‹å†™æ–‡å­—")
        print("  â€¢ âœï¸ æ‰‹å†™è¯†åˆ« - ä¸“é—¨å¤„ç†æ‰‹å†™æ–‡æ¡£")
        print("  â€¢ ğŸ“Š è¡¨æ ¼æå– - ä»å›¾åƒä¸­æå–è¡¨æ ¼æ•°æ®")
        print("  â€¢ ğŸ“‘ æ‰¹é‡å¤„ç† - å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹")
        print()
        
        path = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
        
        if path:
            ocr = Florence2OCR()
            
            if Path(path).is_dir():
                print("\næ£€æµ‹åˆ°æ–‡ä»¶å¤¹ï¼Œæ‰§è¡Œæ‰¹é‡å¤„ç†...")
                ocr.batch_process(path)
            else:
                print("\né€‰æ‹©å¤„ç†æ¨¡å¼:")
                print("1. æ™®é€šOCR")
                print("2. æ‰‹å†™æ–‡æ¡£è¯†åˆ«")
                print("3. è¡¨æ ¼æå–")
                print("4. å¸¦åŒºåŸŸçš„OCR")
                
                choice = input("è¯·é€‰æ‹© (1-4): ").strip()
                
                if choice == '2':
                    results = ocr.process_handwritten(path)
                    print("\nè¯†åˆ«ç»“æœ:")
                    print(results['cleaned_text'])
                elif choice == '3':
                    df = ocr.extract_table(path)
                    print("\næå–çš„è¡¨æ ¼:")
                    print(df)
                elif choice == '4':
                    result = ocr.ocr_image(path, "ocr_with_region")
                    print("\nè¯†åˆ«ç»“æœ:")
                    print(result['text'])
                else:
                    result = ocr.ocr_image(path)
                    print("\nè¯†åˆ«ç»“æœ:")
                    print(result['text'])
    else:
        main()
