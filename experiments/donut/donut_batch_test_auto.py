#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Donut æ‰¹é‡æµ‹è¯•å™¨ï¼ˆBatch Testerï¼‰ + è‡ªåŠ¨è·¯ç”±
----------------------------------------
â€¢ éå†è¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
â€¢ æ”¯æŒä¸¤ç§å·¥ä½œæ–¹å¼ï¼š
  1) ç›´æ¥æŒ‰ä½ æŒ‡å®šçš„é¢„è®¾ï¼ˆpresetsï¼‰é€ä¸€è¿è¡Œï¼›
  2) **è‡ªåŠ¨è·¯ç”±ï¼ˆ--auto_routeï¼‰**ï¼šå…ˆç”¨â€œæ¢é’ˆâ€åˆ¤å®šé¡µé¢ç±»å‹ï¼ˆè¡¨/å…¬å¼/å›¾/æ··åˆï¼‰ï¼Œå†è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„é¢„è®¾ï¼›
â€¢ åŒä¸€å¼ å›¾ç‰‡çš„æ‰€æœ‰æ¨¡å¼ç»“æœæ±‡æ€»åˆ° **åŒä¸€ä¸ª** JSON æ–‡ä»¶ä¸­ï¼Œä¾¿äºå¯¹æ¯”
â€¢ ä¿ç•™æ•°æ®è·¯å¾„ä¸æ¨¡å‹/é¢„è®¾å ä½ï¼Œä¾¿äºä½ æŒ‰éœ€ä¿®æ”¹

ç¯å¢ƒå»ºè®®ï¼štransformers >= 4.38, torch >= 2.0, Pillow

å®‰è£…ç¤ºä¾‹ï¼ˆä½¿ç”¨ uvï¼‰ï¼š
# 1) åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
uv venv .venv
# macOS/Linux
source .venv/bin/activate
# Windows PowerShell
# .venv\Scripts\Activate.ps1

# 2) å®‰è£…ä¾èµ–
uv pip install -U torch torchvision pillow transformers accelerate

è¯´æ˜ï¼š
- Donut æ˜¯ OCRâ€‘free çš„æ–‡æ¡£ç†è§£æ¨¡å‹ã€‚ä¸åŒ checkpoint å¾€å¾€éœ€è¦ä¸åŒçš„ä»»åŠ¡å‰ç¼€ï¼ˆtask promptï¼‰ã€‚
  å¦‚æœä½ ä½¿ç”¨çš„æƒé‡åœ¨ Hugging Face README é‡Œç»™äº†ç¤ºèŒƒ promptï¼Œè¯·æŠŠå®ƒå¡«åˆ°ä¸‹æ–¹ PRESETS çš„
  "task_prompt" å­—æ®µã€‚
- å¯¹â€œæ•™æç±»é¡µé¢çš„é€šç”¨è¯»æ–‡æœ¬ï¼ˆpseudoâ€‘OCRï¼‰â€ï¼Œä¼˜å…ˆå°è¯• SynthDoG ç³»åˆ—å¾®è°ƒæƒé‡ã€‚
  ç¤ºä¾‹ï¼š"naver-clova-ix/donut-base-finetuned-synthdog"ï¼ˆé€šç”¨æ–‡æœ¬è¯»å–ï¼‰
- è‹¥æ˜¯æ–‡æ¡£é—®ç­”ï¼ˆDocVQAï¼‰ï¼Œä½¿ç”¨ *_docvqa å¾®è°ƒæƒé‡ï¼Œå¹¶åœ¨ prompt ä¸­æä¾›é—®é¢˜ã€‚

è„šæœ¬è¿˜ä¼šæŠŠèƒ½åŠ›ä¿¡æ¯ï¼ˆç”Ÿæˆå‚æ•°ã€tokenizer æ–°å¢ tokenã€å›¾åƒå¤„ç†é…ç½®ï¼‰
å¯¼å‡ºåˆ° <output_dir>/capabilities.jsonï¼Œä»¥ä¾¿æ’æŸ¥ä¸å¤ç°å®éªŒã€‚
"""
from __future__ import annotations
import argparse
import json
import os
import sys
import time
import inspect
import re
from dataclasses import dataclass, asdict
from typing import Dict, Any, List, Optional

from PIL import Image
import torch
from transformers import VisionEncoderDecoderModel
from transformers import DonutProcessor

# ---------------------------
# é»˜è®¤é…ç½®ï¼ˆä½ å¯ä»¥æ”¹è¿™é‡Œï¼‰
# ---------------------------
DEFAULT_INPUT_DIR = "data/pdf_ocr_samples"   # ä½¿ç”¨å·²æœ‰çš„æ ·æœ¬å›¾ç‰‡ç›®å½•
DEFAULT_OUTPUT_DIR = "output/donut_results"   # ç»“æœä¿å­˜ç›®å½•
DEFAULT_MODEL_ID = "naver-clova-ix/donut-base"  # é€šç”¨åŸºç¡€æ¨¡å‹
# å…¶ä»–åŸºç¡€æ¨¡å‹å¯ç”¨ï¼š"naver-clova-ix/donut-base"

# è‹¥ GPU æ˜¾å­˜å…è®¸ï¼Œåœ¨ CUDA ä¸Šç”¨ FP16 å¯æå‡æ¨ç†é€Ÿåº¦
DEFAULT_USE_FP16 = True

# æ˜¯å¦é»˜è®¤å¯ç”¨è‡ªåŠ¨è·¯ç”±ï¼ˆä¹Ÿå¯ç”¨ --auto_route å¼€å…³è¦†ç›–ï¼‰
DEFAULT_AUTO_ROUTE = False

# ---------------------------
# é¢„è®¾å‚æ•°æ¨¡æ¿ï¼ˆPresetsï¼‰
# ---------------------------
# æ¯ä¸ªé¢„è®¾æ§åˆ¶ä¸‰ç±»å‚æ•°ï¼š
#   - task_promptï¼šè§£ç å™¨çš„ä»»åŠ¡å‰ç¼€/æç¤ºï¼ˆä¸åŒ checkpoint å¯èƒ½ä¸åŒï¼‰
#   - genï¼šä¼ ç»™ model.generate çš„ç”Ÿæˆå‚æ•°
#   - iprocï¼šæœ¬æ¬¡è¿è¡Œçš„å›¾åƒé¢„å¤„ç†è¦†ç›–é¡¹ï¼ˆä¾‹å¦‚é‡æ–°è®¾å®šè¾“å…¥å°ºå¯¸ï¼‰
#
# é’ˆå¯¹â€œæ•™æé¡µåŒ…å«è¡¨æ ¼/å›¾ç‰‡/å…¬å¼â€çš„åœºæ™¯ï¼Œç»™å‡ºè‹¥å¹²å¯ç›´æ¥ä½¿ç”¨çš„é¢„è®¾ï¼›
# ä½ å¯ä»¥è‡ªç”±å¢åˆ æˆ–è°ƒæ•´ã€‚
PRESETS: Dict[str, Dict[str, Any]] = {
    # é€Ÿåº¦å¿«ã€ç¡®å®šæ€§å¼ºçš„åˆç­›ï¼›å…ˆçœ‹èƒ½å¦é¡ºç•…è¯»å‡ºæ­£æ–‡ã€‚
    "fast_draft": {
        "task_prompt": "",  # è‹¥ checkpoint éœ€è¦å¦‚ "<s_synthdog>" ç­‰èµ·å§‹ tokenï¼Œè¯·å†™åœ¨è¿™é‡Œ
        "gen": {
            "max_new_tokens": 384,
            "num_beams": 1,
            "do_sample": False,
            "early_stopping": True,
            "repetition_penalty": 1.05,
            "no_repeat_ngram_size": 3,
        },
        "iproc": {
            # ç¤ºä¾‹ï¼šDonut é»˜è®¤å¸¸ç”¨çŸ­è¾¹çº¦ 1280ï¼›
            # å¦‚éœ€æ‰‹åŠ¨è®¾å®šå°ºå¯¸ï¼Œå–æ¶ˆæ³¨é‡Šï¼š
            # "size": {"height": 1280, "width": 960},
        },
        "description": "å¿«é€Ÿä¸”ç¡®å®šæ€§çš„ç²—è¯»ï¼Œé€‚åˆå…ˆçœ‹é¡µé¢ä¸»ä½“å†…å®¹ã€‚"},

    # å¹³è¡¡çš„æŸæœç´¢ï¼Œæå‡ç»“æ„ç¨³å®šæ€§ï¼Œå‡å°‘åˆ—è¡¨/è¡¨æ ¼é‡å¤ã€‚
    "balanced_beam": {
        "task_prompt": "",
        "gen": {
            "max_new_tokens": 768,
            "num_beams": 4,
            "do_sample": False,
            "early_stopping": True,
            "repetition_penalty": 1.1,
            "no_repeat_ngram_size": 4,
            "length_penalty": 0.95,
        },
        "iproc": {
            # å¯æŒ‰éœ€æé«˜è¾“å…¥åˆ†è¾¨ç‡ï¼š
            # "size": {"height": 1440, "width": 1024},
        },
        "description": "ç»“æ„æ›´å¹²å‡€ï¼Œé€‚åˆå«è¡¨æ ¼ä¸æ··åˆå†…å®¹çš„é¡µé¢ã€‚"},

    # é¢å‘é•¿é¡µé¢ï¼ˆå¤šå›¾/å¤šå…¬å¼/å†…å®¹å¯†é›†ï¼‰ï¼Œä»¥å®Œæ•´æ€§ä¸ºä¼˜å…ˆï¼Œç‰ºç‰²ä¸€ç‚¹é€Ÿåº¦ã€‚
    "long_page_strict": {
        "task_prompt": "",
        "gen": {
            "max_new_tokens": 1400,
            "num_beams": 3,
            "do_sample": False,
            "early_stopping": False,
            "repetition_penalty": 1.12,
            "no_repeat_ngram_size": 4,
        },
        "iproc": {
            # æ˜¾å­˜å…è®¸æ—¶å¯é€‚åº¦å¢å¤§è¾“å…¥å°ºå¯¸ï¼š
            # "size": {"height": 1600, "width": 1130},
        },
        "description": "é¢å‘é•¿é¡µä¸å¯†é›†ä¿¡æ¯ï¼Œå°½é‡è¦†ç›–æ›´å¤šå†…å®¹ã€‚"},

    # é¼“åŠ±æŠŠæ¸…æ™°çš„å…¬å¼æŒ‰ LaTeX é£æ ¼è½¬å†™ï¼›ä¿æŒç¡®å®šæ€§ã€‚
    "formula_friendly": {
        # è‹¥æƒé‡æ”¯æŒè‡ªç„¶è¯­è¨€ä»»åŠ¡æç¤ºï¼Œå¯ç”¨ä¸‹è¿°æç¤ºå¼•å¯¼å…¬å¼è½¬å†™é£æ ¼ï¼š
        "task_prompt": "Transcribe math as LaTeX when clear; keep original text for body.",
        "gen": {
            "max_new_tokens": 1024,
            "num_beams": 4,
            "do_sample": False,
            "early_stopping": True,
            "repetition_penalty": 1.15,
            "no_repeat_ngram_size": 3,
            "length_penalty": 1.0,
        },
        "iproc": {},
        "description": "å¯¹å…¬å¼æ›´å‹å¥½ï¼Œåå‘ LaTeX å¼è½¬å†™ï¼Œæ­£æ–‡ä¿æŒåŸæ–‡é£æ ¼ã€‚"},

    # å°è¯•æŠŠè¡¨æ ¼æ¸²æŸ“ä¸º Markdownï¼›ç»“æ„ä¸ç¡®å®šæ—¶é€‚å½“ä½¿ç”¨é‡‡æ ·æœ‰æ—¶æ›´ç¨³ã€‚
    "table_markdown": {
        "task_prompt": "If tables are present, render them as GitHub-flavored Markdown; otherwise read text.",
        "gen": {
            "max_new_tokens": 900,
            "num_beams": 1,
            "do_sample": True,
            "temperature": 0.7,
            "top_p": 0.9,
            "repetition_penalty": 1.05,
            "no_repeat_ngram_size": 3,
        },
        "iproc": {},
        "description": "é¼“åŠ±ç”Ÿæˆ Markdown è¡¨æ ¼ï¼›é‡åˆ°ä¸ç¨³å®šç‰ˆé¢æ—¶æ›´çµæ´»ã€‚"},

    # ä¸€å¥è¯çº§åˆ«çš„é¡µé¢æ‘˜è¦/è¯´æ˜ï¼Œä¾¿äºå¿«é€Ÿæµè§ˆã€‚
    "page_summary": {
        "task_prompt": "Provide a concise one-sentence summary of the page content.",
        "gen": {
            "max_new_tokens": 64,
            "num_beams": 1,
            "do_sample": True,
            "temperature": 0.8,
            "top_p": 0.92,
        },
        "iproc": {},
        "description": "ç”Ÿæˆé¡µé¢çš„ç®€çŸ­æ‘˜è¦ï¼ˆéé€šç”¨è‡ªç„¶å›¾åƒ captioningï¼‰ã€‚"},

    # ===== é€šç”¨ä¸€æŠŠæ¢­ï¼šèƒ½ç»“æ„åŒ–å°±ç»“æ„åŒ–ï¼Œå¤æ‚å°±é™çº§ä¸º caption+è¦ç‚¹ =====
    "universal_doc": {
        "task_prompt": (
            "Analyze the page image and output STRICT JSON with keys: "
            "{"
            "\"page_type\": [\"table\"|\"equation\"|\"figure\"|\"text\"|\"mixed\"], "
            "\"tables_md\": [], \"equations_latex\": [], "
            "\"caption\": \"\", \"text\": \"\"" 
            "}. "
            "Rules: "
            "1) If the page is predominantly a TABLE and small enough, transcribe it exactly as GitHub-Flavored Markdown into tables_md. "
            "2) If the page is predominantly EQUATIONS with little body text, transcribe equations into equations_latex (LaTeX). "
            "3) If the layout is MIXED or too large to reproduce, do NOT hallucinate; return a short caption and key body text; keep tables_md/equations_latex empty. "
            "Always return valid JSON and no text outside JSON."
        ),
        "gen": {
            "max_new_tokens": 1000,
            "num_beams": 4,
            "do_sample": False,
            "early_stopping": True,
            "no_repeat_ngram_size": 4,
            "repetition_penalty": 1.10,
            "length_penalty": 1.0
        },
        "iproc": { "size": {"height": 1440, "width": 1024} },
        "description": "é€šç”¨ presetï¼šç»Ÿä¸€ JSON åè®®ï¼›è¡¨/å¼ä¼˜å…ˆç»“æ„åŒ–ï¼Œå¤æ‚åˆ™é™çº§æ‘˜è¦ã€‚"},

    # ===== è·¯ç”±æ¢é’ˆï¼šæçŸ­ JSON åˆ†ç±»è¾“å‡ºï¼ˆè¡¨/å¼/å›¾/æ–‡æœ¬/æ··åˆ & è¡¨æ ¼å¤§å° & ç½®ä¿¡åº¦ï¼‰ =====
    "router_probe": {
        "task_prompt": (
            "Classify the page layout. Output STRICT JSON ONLY with keys: "
            "{\"is_table\": bool, \"is_equation\": bool, \"is_figure\": bool, "
            " \"is_text\": bool, \"dominant\": \"table|equation|figure|text|mixed\", "
            " \"table_size\": \"none|small|large\", \"confidence\": number}."
        ),
        "gen": {
            "max_new_tokens": 48,
            "num_beams": 1,
            "do_sample": False,
            "early_stopping": True
        },
        "iproc": { "size": {"height": 1280, "width": 960} },
        "description": "å¿«é€Ÿåˆ¤åˆ«ç‰ˆå¼ç±»å‹+è¡¨æ ¼å¤§å°+ç½®ä¿¡åº¦ã€‚"},

    # â€”â€” å…¬å¼çŸ­å›¾ï¼šåªè½¬å†™å¯è§å…¬å¼ï¼Œå€¾å‘ LaTeXï¼Œå°½é‡å°‘åºŸè¯ â€”â€”
    "eq_compact": {
        "task_prompt": "Transcribe visible equations using LaTeX; keep inline math inline; do not invent symbols.",
        "gen": {
            "max_new_tokens": 160,
            "num_beams": 4,
            "do_sample": False,
            "no_repeat_ngram_size": 2,
            "repetition_penalty": 1.20,
            "early_stopping": True
        },
        "iproc": { "size": {"height": 1024, "width": 768} },
        "description": "çŸ­/å•è¡Œå…¬å¼ï¼Œé«˜ä¿çœŸã€ä½å†—ä½™ã€‚"},

    # â€”â€” è¡¨æ ¼ï¼ˆå°åˆ°ä¸­ç­‰ï¼‰ï¼šç²¾ç¡®å¤åˆ»ä¸º Markdown â€”â€”
    "table_strict_md": {
        "task_prompt": "Extract all tables as GitHub-Flavored Markdown. Preserve headers, numbers, and punctuation exactly. Do not summarize.",
        "gen": {
            "max_new_tokens": 480,
            "num_beams": 4,
            "do_sample": False,
            "no_repeat_ngram_size": 4,
            "repetition_penalty": 1.10,
            "length_penalty": 1.00
        },
        "iproc": { "size": {"height": 1440, "width": 1024} },
        "description": "å°/ä¸­è¡¨æ ¼çš„ä¸¥è°¨å¤åˆ»ã€‚"},

    # â€”â€” å®½/é•¿è¡¨æ ¼ï¼šå…è®¸æ›´é•¿è¾“å‡º â€”â€”
    "wide_table_md": {
        "task_prompt": "If the table is wide, split into multiple Markdown tables by logical sections. Preserve header rows; avoid wrapping cell content.",
        "gen": {
            "max_new_tokens": 1400,
            "num_beams": 3,
            "do_sample": False,
            "no_repeat_ngram_size": 4,
            "repetition_penalty": 1.12,
            "early_stopping": False
        },
        "iproc": { "size": {"height": 1600, "width": 1130} },
        "description": "å®½/é•¿è¡¨ï¼ˆç»“æœè¡¨ï¼‰æ›´ç¨³ã€‚"},

    # â€”â€” å›¾ç¤º+è¯´æ˜ï¼šæå–ç»“æ„åŒ–è¦ç‚¹ï¼ˆæœ€å¤š 5 æ¡ï¼‰ â€”â€”
    "figure_bullets": {
        "task_prompt": "Summarize the figure with up to 5 bullet points: (1) key entities, (2) relationships, (3) notable labels/values.",
        "gen": {
            "max_new_tokens": 180,
            "num_beams": 1,
            "do_sample": True,
            "temperature": 0.7,
            "top_p": 0.9
        },
        "iproc": { "size": {"height": 1280, "width": 960} },
        "description": "æ¶æ„å›¾/ç¤ºæ„å›¾çš„è¦ç‚¹æ‘˜è¦ã€‚"},
}


# ---------------------------
# æ•°æ®ç»“æ„
# ---------------------------
@dataclass
class RunResult:
    preset: str
    prompt: str
    image_processor_overrides: Dict[str, Any]
    generation_kwargs: Dict[str, Any]
    output_text: Optional[str]
    output_json: Optional[Dict[str, Any]]
    runtime_sec: float
    num_generated_tokens: Optional[int]
    error: Optional[str]


# ---------------------------
# å·¥å…·å‡½æ•°
# ---------------------------
IMG_EXTS = {".png", ".jpg", ".jpeg", ".webp", ".bmp", ".tif", ".tiff"}

def list_images(folder: str) -> List[str]:
    """é€’å½’åˆ—å‡ºç›®å½•ä¸‹æ‰€æœ‰å—æ”¯æŒçš„å›¾ç‰‡è·¯å¾„ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰ã€‚"""
    files = []
    for root, _, names in os.walk(folder):
        for n in sorted(names):
            if os.path.splitext(n.lower())[1] in IMG_EXTS:
                files.append(os.path.join(root, n))
    return files


def ensure_dir(p: str):
    """è‹¥ç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»ºã€‚"""
    os.makedirs(p, exist_ok=True)


def save_json(path: str, obj: Any):
    """ä»¥ UTFâ€‘8 å’Œç¼©è¿›å†™å…¥ JSON æ–‡ä»¶ã€‚"""
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)


def load_json(path: str) -> Any:
    """è¯»å– JSON æ–‡ä»¶ä¸º Python å¯¹è±¡ã€‚"""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def image_processor_apply_overrides(processor: DonutProcessor, overrides: Dict[str, Any]):
    """å®‰å…¨åœ°åº”ç”¨å¸¸ç”¨çš„å›¾åƒå¤„ç†è¦†ç›–é¡¹ï¼ˆå½“å‰ä»…æ”¯æŒ size: {height, width}ï¼‰ã€‚"""
    ip = processor.image_processor
    if not overrides:
        return
    if "size" in overrides and isinstance(overrides["size"], dict):
        size = overrides["size"]
        if {"height", "width"}.issubset(size.keys()):
            ip.size = {"height": int(size["height"]), "width": int(size["width"]) }


def dump_capabilities(output_dir: str, model: VisionEncoderDecoderModel, processor: DonutProcessor):
    """å¯¼å‡ºå½“å‰æ¨¡å‹/å¤„ç†å™¨çš„èƒ½åŠ›æ¦‚è§ˆï¼Œä¾¿äºè°ƒå‚ä¸æ’é”™ã€‚"""
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    ensure_dir(output_dir)
    cap = {}
    # ç”Ÿæˆé…ç½®
    try:
        cap["generation_config"] = model.generation_config.to_dict()
    except Exception as e:
        cap["generation_config_error"] = str(e)
    # generate æ–¹æ³•ç­¾åï¼ˆæŸ¥çœ‹å¯ç”¨å‚æ•°ï¼‰
    try:
        sig = str(inspect.signature(model.generate))
        cap["model_generate_signature"] = sig
    except Exception as e:
        cap["model_generate_signature_error"] = str(e)
    # åˆ†è¯å™¨æ–°å¢è¯ï¼ˆå¸¸åŒ…å«ä»»åŠ¡ tokenï¼Œå¦‚ <s_xxx>ï¼‰
    try:
        added = list(processor.tokenizer.get_added_vocab().keys())
        cap["tokenizer_added_tokens"] = sorted(added)
    except Exception as e:
        cap["tokenizer_added_tokens_error"] = str(e)
    # å›¾åƒå¤„ç†å™¨é…ç½®
    try:
        cap["image_processor_config"] = getattr(processor.image_processor, "config", {})
        # æŸäº›å­—æ®µä¸å¯åºåˆ—åŒ–ï¼Œé™çº§ä¸ºå¸¸è§å±æ€§å­—å…¸
        if not isinstance(cap["image_processor_config"], dict):
            cap["image_processor_config"] = {
                "size": getattr(processor.image_processor, "size", None),
                "do_resize": getattr(processor.image_processor, "do_resize", None),
                "resample": getattr(processor.image_processor, "resample", None),
            }
    except Exception as e:
        cap["image_processor_config_error"] = str(e)

    save_json(os.path.join(output_dir, "capabilities.json"), cap)


def extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:
    """ä»ä»»æ„æ–‡æœ¬ä¸­å°½é‡æŠ½å–ç¬¬ä¸€ä¸ª JSON å¯¹è±¡ã€‚å¤±è´¥è¿”å› Noneã€‚"""
    if not text:
        return None
    try:
        # ç›´æ¥ parse
        return json.loads(text)
    except Exception:
        pass
    # å¯»æ‰¾æœ€å¤–å±‚èŠ±æ‹¬å·
    try:
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1 and end > start:
            snippet = text[start:end+1]
            # å»æ‰å¯èƒ½çš„å¤šä½™å°¾éšæ ‡ç‚¹/æ§åˆ¶å­—ç¬¦
            snippet = re.sub(r"[^ -~\t]", "", snippet)
            return json.loads(snippet)
    except Exception:
        return None
    return None


# ---------------------------
# æ ¸å¿ƒï¼šå¯¹å•å¼ å›¾ç‰‡æŒ‰æŸä¸ªé¢„è®¾è¿è¡Œä¸€æ¬¡
# ---------------------------
@torch.inference_mode()
def run_once(
    model: VisionEncoderDecoderModel,
    processor: DonutProcessor,
    device: torch.device,
    image_path: str,
    preset_name: str,
    preset_cfg: Dict[str, Any],
) -> RunResult:
    t0 = time.time()
    error = None
    output_text = None
    output_json = None
    num_gen_tokens: Optional[int] = None

    # è¯»å–å›¾ç‰‡å¹¶è½¬ä¸º RGB
    img = Image.open(image_path).convert("RGB")

    # ä¸´æ—¶åº”ç”¨å›¾åƒå¤„ç†è¦†ç›–å‚æ•°
    original_size = dict(getattr(processor.image_processor, "size", {}))
    image_processor_apply_overrides(processor, preset_cfg.get("iproc", {}))

    try:
        task_prompt = str(preset_cfg.get("task_prompt", ""))

        inputs = processor(images=img, text=task_prompt, return_tensors="pt")
        inputs = {k: v.to(device) for k, v in inputs.items()}

        gen_kwargs = dict(preset_cfg.get("gen", {}))
        # ç¡®ä¿ pad/eos token è®¾ç½®å¦¥å½“ï¼ˆä» processor æ³¨å…¥ï¼‰
        if model.config.pad_token_id is None and hasattr(processor.tokenizer, "pad_token_id"):
            model.config.pad_token_id = processor.tokenizer.pad_token_id
        if model.config.eos_token_id is None and hasattr(processor.tokenizer, "eos_token_id"):
            model.config.eos_token_id = processor.tokenizer.eos_token_id

        # ç”Ÿæˆ
        out = model.generate(**inputs, **gen_kwargs)
        # è®°å½•ç”Ÿæˆ token æ•°ï¼ˆè‹¥å¯ç”¨ï¼‰
        if hasattr(out, "sequences"):
            seq = out.sequences
        else:
            seq = out
        num_gen_tokens = int(seq.shape[-1]) if hasattr(seq, "shape") else None

        # è§£ç æ–‡æœ¬ï¼›è‹¥å¯è§£æä¸ºç»“æ„åŒ– JSONï¼Œåˆ™åŒæ—¶ç»™å‡º
        decoded = processor.batch_decode(seq, skip_special_tokens=False)[0]
        output_text = decoded
        try:
            output_json = processor.token2json(decoded)
        except Exception:
            output_json = None

    except Exception as e:
        error = f"{type(e).__name__}: {e}"
    finally:
        # æ¢å¤å›¾åƒå¤„ç†å™¨çš„åŸå§‹å°ºå¯¸è®¾ç½®
        if original_size:
            processor.image_processor.size = original_size

    dt = time.time() - t0
    return RunResult(
        preset=preset_name,
        prompt=task_prompt,
        image_processor_overrides=preset_cfg.get("iproc", {}),
        generation_kwargs=preset_cfg.get("gen", {}),
        output_text=output_text,
        output_json=output_json,
        runtime_sec=dt,
        num_generated_tokens=num_gen_tokens,
        error=error,
    )


def pick_presets_by_probe(probe: Optional[Dict[str, Any]]) -> List[str]:
    """æ ¹æ®æ¢é’ˆ JSON é€‰æ‹©åç»­é¢„è®¾ã€‚"""
    p = probe or {}
    dom = str(p.get("dominant", "mixed")).lower()
    size = str(p.get("table_size", "none")).lower()
    try:
        conf = float(p.get("confidence", 0.0))
    except Exception:
        conf = 0.0

    # é«˜ç½®ä¿¡åº¦ï¼Œç›´è¾¾ä¸“é¡¹
    if conf >= 0.7:
        if dom == "equation":
            return ["eq_compact"] if "eq_compact" in PRESETS else ["formula_friendly"]
        if dom == "table" and size == "small":
            return ["table_strict_md"] if "table_strict_md" in PRESETS else ["table_markdown"]
        if dom == "table" and size == "large":
            return ["wide_table_md"] if "wide_table_md" in PRESETS else ["long_page_strict"]
        if dom in ("figure", "mixed"):
            return ["figure_bullets", "page_summary"] if "figure_bullets" in PRESETS else ["page_summary"]
        if dom == "text":
            return ["balanced_beam"]

    # å…œåº•ï¼šé€šç”¨ preset
    return ["universal_doc"]


# ---------------------------
# ä¸»æµç¨‹ï¼ˆæ‰¹é‡éå†å›¾ç‰‡å¹¶èšåˆç»“æœï¼‰
# ---------------------------

def main():
    parser = argparse.ArgumentParser(description="å¯¹ä¸€ä¸ªå›¾ç‰‡æ–‡ä»¶å¤¹æ‰¹é‡æµ‹è¯• Donutï¼ˆæ”¯æŒè‡ªåŠ¨è·¯ç”±ï¼‰")
    parser.add_argument("--input_dir", default=DEFAULT_INPUT_DIR, help="æ ·æœ¬å›¾ç‰‡ç›®å½•")
    parser.add_argument("--output_dir", default=DEFAULT_OUTPUT_DIR, help="è¯†åˆ«ç»“æœä¿å­˜ç›®å½•ï¼ˆæŒ‰å›¾ç‰‡åç”Ÿæˆ JSONï¼‰")
    parser.add_argument("--model_id", default=DEFAULT_MODEL_ID, help="HF æ¨¡å‹ ID æˆ–æœ¬åœ° checkpoint è·¯å¾„ï¼Œå¦‚ naver-clova-ix/donut-base-finetuned-synthdog")
    parser.add_argument("--device", default=None, choices=[None, "cuda", "mps", "cpu"], help="å¼ºåˆ¶ä½¿ç”¨çš„è®¾å¤‡ï¼ˆé»˜è®¤è‡ªåŠ¨é€‰æ‹©ï¼‰")
    parser.add_argument("--fp16", action="store_true", help="åœ¨ CUDA ä¸Šå¯ç”¨ FP16ï¼ˆè‹¥æœªæŒ‡å®šï¼Œä»¥è„šæœ¬é»˜è®¤ä¸ºå‡†ï¼‰")
    parser.add_argument("--no-fp16", dest="fp16", action="store_false", help="ç¦ç”¨ FP16")
    parser.set_defaults(fp16=DEFAULT_USE_FP16)
    parser.add_argument("--presets", nargs="*", default=list(PRESETS.keys()), help="è¦è¿è¡Œçš„é¢„è®¾åï¼ˆç•™ç©º=å…¨éƒ¨ï¼›è‡ªåŠ¨è·¯ç”±æ—¶å¿½ç•¥ï¼‰")
    parser.add_argument("--auto_route", action="store_true", help="å¯ç”¨è‡ªåŠ¨è·¯ç”±ï¼šå…ˆè·‘ router_probeï¼Œå†æŒ‰ç»“æœé€‰æ‹©åç»­é¢„è®¾")
    parser.add_argument("--save_capabilities", action="store_true", help="å¯¼å‡ºæ¨¡å‹/å¤„ç†å™¨èƒ½åŠ›æ¦‚è§ˆåˆ° capabilities.json")
    parser.add_argument("--limit", type=int, default=None, help="æœ€å¤šåªå¤„ç†å‰ N å¼ å›¾ç‰‡")

    args = parser.parse_args()

    input_dir = args.input_dir
    output_dir = args.output_dir
    ensure_dir(output_dir)

    # è®¾å¤‡é€‰æ‹©é€»è¾‘
    if args.device:
        device_str = args.device
    else:
        if torch.cuda.is_available():
            device_str = "cuda"
        elif torch.backends.mps.is_available():
            device_str = "mps"
        else:
            device_str = "cpu"
    device = torch.device(device_str)

    # åŠ è½½æ¨¡å‹ä¸å¤„ç†å™¨
    torch.set_grad_enabled(False)
    dtype = torch.float16 if (device_str == "cuda" and args.fp16) else torch.float32
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹ {args.model_id} åˆ° {device_str} (dtype={dtype}) ...")
    processor = DonutProcessor.from_pretrained(args.model_id)
    model = VisionEncoderDecoderModel.from_pretrained(args.model_id, torch_dtype=dtype)
    model.to(device)
    model.eval()

    # å¯é€‰ï¼šå¯¼å‡ºèƒ½åŠ›æ¦‚è§ˆ
    if args.save_capabilities:
        dump_capabilities(output_dir, model, processor)
        print(f"å·²ä¿å­˜èƒ½åŠ›æ¦‚è§ˆ: {os.path.join(output_dir, 'capabilities.json')}")

    # åˆ—å‡ºå›¾ç‰‡
    images = list_images(input_dir)
    if args.limit is not None:
        images = images[: args.limit]
    if not images:
        print(f"æœªåœ¨è¯¥ç›®å½•æ‰¾åˆ°å›¾ç‰‡: {input_dir}")
        sys.exit(1)

    # å¦‚æœä¸èµ°è‡ªåŠ¨è·¯ç”±ï¼Œå‡†å¤‡å›ºå®šçš„é¢„è®¾é›†åˆ
    chosen_presets = []
    if not args.auto_route:
        for name in args.presets:
            if name not in PRESETS:
                print(f"[è­¦å‘Š] æœªæ‰¾åˆ°é¢„è®¾ '{name}'ï¼Œå·²è·³è¿‡ã€‚")
                continue
            chosen_presets.append((name, PRESETS[name]))
        if not chosen_presets:
            print("æœªé€‰æ‹©åˆ°æœ‰æ•ˆçš„é¢„è®¾ã€‚")
            sys.exit(1)

    # é€å›¾å¤„ç†å¹¶èšåˆå†™å…¥ JSON
    for idx, img_path in enumerate(images, 1):
        rel = os.path.relpath(img_path, input_dir)
        stem = os.path.splitext(os.path.basename(img_path))[0]
        out_file = os.path.join(output_dir, f"{stem}.json")
        
        # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
        progress_percent = (idx / len(images)) * 100
        print(f"\nğŸ”„ è¿›åº¦: [{idx}/{len(images)}] - {progress_percent:.1f}%")
        print(f"==> {rel} : {('è‡ªåŠ¨è·¯ç”±' if args.auto_route else 'è¿è¡Œ ' + str(len(chosen_presets)) + ' ä¸ªé¢„è®¾')}")

        # è‹¥è¯¥å›¾ç‰‡å·²æœ‰èšåˆç»“æœåˆ™è¯»å–ï¼ˆä»¥ä¾¿è¿½åŠ ï¼‰
        if os.path.exists(out_file):
            try:
                aggregate = load_json(out_file)
            except Exception:
                aggregate = {}
        else:
            aggregate = {}

        # åˆå§‹åŒ–/è§„èŒƒåŒ–èšåˆç»“æ„
        if not isinstance(aggregate, dict):
            aggregate = {}
        aggregate.setdefault("image", img_path)
        aggregate.setdefault("model_id", args.model_id)
        aggregate.setdefault("created_at", time.strftime("%Y-%m-%d %H:%M:%S"))
        aggregate.setdefault("results", [])

        if args.auto_route:
            # 1) è·‘æ¢é’ˆ
            probe_res = run_once(model, processor, device, img_path, "router_probe", PRESETS["router_probe"]) 
            probe_parsed = extract_json_from_text(probe_res.output_text or "") or probe_res.output_json

            # è®°å½•æ¢é’ˆç»“æœ
            rec_probe = asdict(probe_res)
            rec_probe["parsed_json"] = probe_parsed
            rec_probe["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
            aggregate["results"].append(rec_probe)

            # 2) ç”±æ¢é’ˆé€‰æ‹©åç»­é¢„è®¾
            to_run = pick_presets_by_probe(probe_parsed)
            # 3) è·‘åç»­é¢„è®¾
            for preset_idx, name in enumerate(to_run, 1):
                if name not in PRESETS:
                    print(f"[è­¦å‘Š] é¢„è®¾ '{name}' æœªå®šä¹‰ï¼Œè·³è¿‡ã€‚")
                    continue
                
                # æ˜¾ç¤ºå­è¿›åº¦
                sub_progress = (preset_idx / len(to_run)) * 100
                print(f"  - é¢„è®¾: {name} [{preset_idx}/{len(to_run)}] - {sub_progress:.1f}%")
                
                res = run_once(model, processor, device, img_path, name, PRESETS[name])
                record = asdict(res)
                record["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
                aggregate["results"].append(record)
                
                # æ˜¾ç¤ºç»“æœæ‘˜è¦
                if res.error:
                    print(f"    âŒ é”™è¯¯: {res.error}")
                else:
                    text_preview = res.output_text[:50] + "..." if res.output_text and len(res.output_text) > 50 else res.output_text
                    print(f"    âœ… ç”¨æ—¶: {res.runtime_sec:.2f}ç§’, è¾“å‡ºé•¿åº¦: {len(res.output_text or '') if res.output_text else 0}å­—ç¬¦")

        else:
            # å›ºå®šé¢„è®¾æµç¨‹
            for preset_idx, (preset_name, preset_cfg) in enumerate(chosen_presets, 1):
                # æ˜¾ç¤ºå­è¿›åº¦
                sub_progress = (preset_idx / len(chosen_presets)) * 100
                print(f"  - é¢„è®¾: {preset_name} [{preset_idx}/{len(chosen_presets)}] - {sub_progress:.1f}%")
                
                res = run_once(model, processor, device, img_path, preset_name, preset_cfg)
                record = asdict(res)
                record["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
                aggregate["results"].append(record)
                
                # æ˜¾ç¤ºç»“æœæ‘˜è¦
                if res.error:
                    print(f"    âŒ é”™è¯¯: {res.error}")
                else:
                    text_preview = res.output_text[:50] + "..." if res.output_text and len(res.output_text) > 50 else res.output_text
                    print(f"    âœ… ç”¨æ—¶: {res.runtime_sec:.2f}ç§’, è¾“å‡ºé•¿åº¦: {len(res.output_text or '') if res.output_text else 0}å­—ç¬¦")

        # è®°å½•å·²è¿è¡Œçš„é¢„è®¾åï¼ˆè¿½åŠ å¼ï¼‰
        already = set(aggregate.get("presets_run", []))
        if args.auto_route:
            already.update(["router_probe"])  # æ¢é’ˆ
            # æŠŠæœ¬æ¬¡çœŸæ­£è·‘çš„é¢„è®¾åä¹Ÿå†™è¿›å»
            # ä»æœ€æ–°è¿½åŠ çš„è®°å½•ä¸­æŠ“ preset å­—æ®µ
            for r in aggregate["results"][-3:]:  # ç®€åŒ–ï¼šæœ€è¿‘å‡ æ¡é€šå¸¸å°±æ˜¯æœ¬æ¬¡
                if isinstance(r, dict) and r.get("preset"):
                    already.add(r["preset"]) 
        else:
            already.update(name for name, _ in (chosen_presets or []))
        aggregate["presets_run"] = sorted(list(already))

        save_json(out_file, aggregate)
        print(f"å·²ä¿å­˜: {out_file}")

    print("\nå…¨éƒ¨å®Œæˆã€‚")


if __name__ == "__main__":
    main()
