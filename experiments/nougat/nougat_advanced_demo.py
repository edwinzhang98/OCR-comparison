#!/usr/bin/env python3
"""
Nougat é«˜çº§å‚æ•°æ¼”ç¤ºè„šæœ¬
å±•ç¤ºæ‰€æœ‰å¯é…ç½®å‚æ•°çš„ä½¿ç”¨æ–¹æ³•
"""

from transformers import NougatProcessor, VisionEncoderDecoderModel
from transformers import GenerationConfig
from PIL import Image
import torch
import time
from pathlib import Path
from typing import Dict, Optional
import json

class NougatAdvancedOCR:
    """Nougaté«˜çº§OCRå¤„ç†å™¨"""
    
    # é¢„å®šä¹‰çš„é…ç½®æ¨¡æ¿
    PRESET_CONFIGS = {
        "fast": {
            "description": "å¿«é€Ÿæ¨¡å¼ - ç‰ºç‰²ä¸€äº›è´¨é‡æ¢å–é€Ÿåº¦",
            "model": "facebook/nougat-small",
            "generation": {
                "max_length": 2048,
                "num_beams": 3,
                "length_penalty": 0.5,
                "early_stopping": True,
                "no_repeat_ngram_size": 2
            }
        },
        "balanced": {
            "description": "å¹³è¡¡æ¨¡å¼ - é€Ÿåº¦å’Œè´¨é‡çš„å¹³è¡¡",
            "model": "facebook/nougat-base",
            "generation": {
                "max_length": 3072,
                "num_beams": 5,
                "length_penalty": 0.6,
                "early_stopping": True,
                "no_repeat_ngram_size": 3
            }
        },
        "quality": {
            "description": "é«˜è´¨é‡æ¨¡å¼ - æœ€ä½³è¯†åˆ«è´¨é‡",
            "model": "facebook/nougat-base",
            "generation": {
                "max_length": 4096,
                "num_beams": 8,
                "length_penalty": 0.7,
                "early_stopping": False,
                "no_repeat_ngram_size": 4,
                "num_beam_groups": 2,
                "diversity_penalty": 0.5
            }
        },
        "math": {
            "description": "æ•°å­¦æ–‡æ¡£æ¨¡å¼ - ä¼˜åŒ–æ•°å­¦å…¬å¼è¯†åˆ«",
            "model": "facebook/nougat-base",
            "generation": {
                "max_length": 5120,
                "num_beams": 10,
                "length_penalty": 0.8,
                "early_stopping": False,
                "no_repeat_ngram_size": 3,
                "temperature": 0.9,
                "top_k": 50
            }
        },
        "table": {
            "description": "è¡¨æ ¼æ–‡æ¡£æ¨¡å¼ - ä¼˜åŒ–è¡¨æ ¼è¯†åˆ«",
            "model": "facebook/nougat-base",
            "generation": {
                "max_length": 4096,
                "num_beams": 6,
                "length_penalty": 0.6,
                "no_repeat_ngram_size": 5,
                "repetition_penalty": 1.2
            }
        }
    }
    
    def __init__(self, preset: str = "balanced", custom_config: Dict = None):
        """
        åˆå§‹åŒ–é«˜çº§OCRå¤„ç†å™¨
        
        Args:
            preset: é¢„è®¾é…ç½® ("fast", "balanced", "quality", "math", "table")
            custom_config: è‡ªå®šä¹‰é…ç½®å­—å…¸
        """
        # é€‰æ‹©é…ç½®
        if custom_config:
            self.config = custom_config
            print(f"ğŸ“‹ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®")
        elif preset in self.PRESET_CONFIGS:
            self.config = self.PRESET_CONFIGS[preset]
            print(f"ğŸ“‹ ä½¿ç”¨é¢„è®¾: {preset} - {self.config['description']}")
        else:
            self.config = self.PRESET_CONFIGS["balanced"]
            print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤é…ç½®: balanced")
        
        # è®¾ç½®è®¾å¤‡
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.dtype = torch.float16 if self.device == "cuda" else torch.float32
        
        # åŠ è½½æ¨¡å‹
        model_name = self.config.get("model", "facebook/nougat-base")
        print(f"ğŸš€ åŠ è½½æ¨¡å‹: {model_name}")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   ç²¾åº¦: {'FP16' if self.dtype == torch.float16 else 'FP32'}")
        
        self.model = VisionEncoderDecoderModel.from_pretrained(
            model_name,
            torch_dtype=self.dtype,
            low_cpu_mem_usage=True,
            use_safetensors=True if Path(f"{model_name}/model.safetensors").exists() else False
        ).to(self.device)
        
        self.processor = NougatProcessor.from_pretrained(model_name)
        
        # è®¾ç½®ç”Ÿæˆé…ç½®
        self.generation_config = GenerationConfig(**self.config.get("generation", {}))
        
        # ç¼–è¯‘æ¨¡å‹ï¼ˆPyTorch 2.0+ï¼‰
        if hasattr(torch, 'compile') and self.device == "cuda":
            print("âš¡ ç¼–è¯‘æ¨¡å‹ä»¥æé«˜æ€§èƒ½...")
            self.model = torch.compile(self.model)
        
        self.model.eval()
        print("âœ… æ¨¡å‹å‡†å¤‡å°±ç»ª\n")
    
    def process_with_params(self, 
                           image_path: str,
                           max_length: Optional[int] = None,
                           num_beams: Optional[int] = None,
                           temperature: Optional[float] = None,
                           top_k: Optional[int] = None,
                           top_p: Optional[float] = None,
                           repetition_penalty: Optional[float] = None,
                           length_penalty: Optional[float] = None,
                           no_repeat_ngram_size: Optional[int] = None,
                           do_sample: Optional[bool] = None,
                           early_stopping: Optional[bool] = None,
                           show_stats: bool = True) -> Dict:
        """
        ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°å¤„ç†å›¾åƒ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            max_length: æœ€å¤§è¾“å‡ºé•¿åº¦
            num_beams: Beamæœç´¢æ•°é‡
            temperature: æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰
            top_k: Top-Ké‡‡æ ·
            top_p: Top-Pé‡‡æ ·
            repetition_penalty: é‡å¤æƒ©ç½š
            length_penalty: é•¿åº¦æƒ©ç½š
            no_repeat_ngram_size: ç¦æ­¢é‡å¤çš„n-gramå¤§å°
            do_sample: æ˜¯å¦ä½¿ç”¨é‡‡æ ·
            early_stopping: æ˜¯å¦æ—©åœ
            show_stats: æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒ…å«ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        print(f"ğŸ“„ å¤„ç†å›¾åƒ: {image_path}")
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        print(f"   å›¾åƒå°ºå¯¸: {image.size}")
        
        # åˆ›å»ºç”Ÿæˆé…ç½®
        gen_kwargs = {}
        
        # æ›´æ–°å‚æ•°ï¼ˆåªæ·»åŠ éNoneçš„å‚æ•°ï¼‰
        if max_length is not None:
            gen_kwargs['max_length'] = max_length
        if num_beams is not None:
            gen_kwargs['num_beams'] = num_beams
        if temperature is not None:
            gen_kwargs['temperature'] = temperature
        if top_k is not None:
            gen_kwargs['top_k'] = top_k
        if top_p is not None:
            gen_kwargs['top_p'] = top_p
        if repetition_penalty is not None:
            gen_kwargs['repetition_penalty'] = repetition_penalty
        if length_penalty is not None:
            gen_kwargs['length_penalty'] = length_penalty
        if no_repeat_ngram_size is not None:
            gen_kwargs['no_repeat_ngram_size'] = no_repeat_ngram_size
        if do_sample is not None:
            gen_kwargs['do_sample'] = do_sample
        if early_stopping is not None:
            gen_kwargs['early_stopping'] = early_stopping
        
        # åˆå¹¶é»˜è®¤é…ç½®
        final_config = {**self.config.get("generation", {}), **gen_kwargs}
        
        if show_stats:
            print("\nâš™ï¸ ç”Ÿæˆå‚æ•°:")
            for key, value in final_config.items():
                print(f"   {key}: {value}")
        
        # é¢„å¤„ç†å›¾åƒ
        start_time = time.time()
        pixel_values = self.processor(image, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(self.device)
        preprocess_time = time.time() - start_time
        
        # ç”Ÿæˆæ–‡æœ¬
        print("\nğŸ”„ ç”Ÿæˆä¸­...")
        start_time = time.time()
        
        with torch.no_grad():
            if self.device == "cuda":
                with torch.cuda.amp.autocast():
                    outputs = self.model.generate(
                        pixel_values,
                        **final_config,
                        bad_words_ids=[[self.processor.tokenizer.unk_token_id]],
                        use_cache=True,
                        pad_token_id=self.processor.tokenizer.pad_token_id,
                        eos_token_id=self.processor.tokenizer.eos_token_id
                    )
            else:
                outputs = self.model.generate(
                    pixel_values,
                    **final_config,
                    bad_words_ids=[[self.processor.tokenizer.unk_token_id]],
                    use_cache=True,
                    pad_token_id=self.processor.tokenizer.pad_token_id,
                    eos_token_id=self.processor.tokenizer.eos_token_id
                )
        
        generation_time = time.time() - start_time
        
        # è§£ç è¾“å‡º
        start_time = time.time()
        generated_text = self.processor.batch_decode(outputs, skip_special_tokens=True)[0]
        
        # åå¤„ç†
        processed_text = self.processor.post_process_generation(
            generated_text, 
            fix_markdown=True
        )
        
        decode_time = time.time() - start_time
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "total_time": preprocess_time + generation_time + decode_time,
            "preprocess_time": preprocess_time,
            "generation_time": generation_time,
            "decode_time": decode_time,
            "output_tokens": outputs.shape[1],
            "text_length": len(processed_text),
            "tokens_per_second": outputs.shape[1] / generation_time if generation_time > 0 else 0
        }
        
        if show_stats:
            print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æ€»ç”¨æ—¶: {stats['total_time']:.2f}ç§’")
            print(f"   - é¢„å¤„ç†: {stats['preprocess_time']:.2f}ç§’")
            print(f"   - ç”Ÿæˆ: {stats['generation_time']:.2f}ç§’")
            print(f"   - è§£ç : {stats['decode_time']:.2f}ç§’")
            print(f"   è¾“å‡ºtokens: {stats['output_tokens']}")
            print(f"   æ–‡æœ¬é•¿åº¦: {stats['text_length']}å­—ç¬¦")
            print(f"   ç”Ÿæˆé€Ÿåº¦: {stats['tokens_per_second']:.1f} tokens/ç§’")
        
        return {
            "text": processed_text,
            "raw_text": generated_text,
            "stats": stats,
            "config": final_config
        }
    
    def compare_configs(self, image_path: str, total_images=None, current_index=None):
        """
        æ¯”è¾ƒä¸åŒé…ç½®çš„æ•ˆæœ
        
        Args:
            image_path: æµ‹è¯•å›¾åƒè·¯å¾„
            total_images: æ€»å›¾ç‰‡æ•°é‡
            current_index: å½“å‰å¤„ç†çš„å›¾ç‰‡ç´¢å¼•
        """
        # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
        if total_images and current_index is not None:
            progress_percent = (current_index / total_images) * 100
            print(f"\nğŸ”„ è¿›åº¦: [{current_index}/{total_images}] - {progress_percent:.1f}%")
            print(f"ğŸ“„ å½“å‰å¤„ç†: {Path(image_path).name}")
            
        print("ğŸ”¬ é…ç½®å¯¹æ¯”å®éªŒ")
        print("=" * 60)
        
        model_name_for_path = self.model.name_or_path.replace("/", "_")
        output_dir = Path("output") / model_name_for_path
        output_dir.mkdir(parents=True, exist_ok=True)
        
        results_for_table = {}
        md_content = f"# Comparison for {Path(image_path).name}\n\n"
        
        # è®¡ç®—é¢„è®¾é…ç½®çš„æ€»æ•°ï¼Œç”¨äºæ˜¾ç¤ºå­è¿›åº¦
        total_presets = len(self.PRESET_CONFIGS)
        
        for preset_idx, (preset_name, preset_config) in enumerate(self.PRESET_CONFIGS.items(), 1):
            # æ˜¾ç¤ºå­è¿›åº¦
            if total_images and current_index is not None:
                sub_progress = (preset_idx / total_presets) * 100
                print(f"\næµ‹è¯•é…ç½®: {preset_name} [{preset_idx}/{total_presets}] - {sub_progress:.1f}%")
            else:
                print(f"\næµ‹è¯•é…ç½®: {preset_name}")
                
            print(f"æè¿°: {preset_config['description']}")
            print("-" * 40)
            
            # ä¸´æ—¶æ›´æ–°é…ç½®
            original_config = self.config
            self.config = preset_config
            self.generation_config = GenerationConfig(**preset_config.get("generation", {}))
            
            # å¤„ç†å›¾åƒ
            result = self.process_with_params(
                image_path,
                show_stats=False
            )
            
            # è®°å½•ç»“æœç”¨äºè¡¨æ ¼
            results_for_table[preset_name] = {
                "time": result['stats']['total_time'],
                "length": result['stats']['text_length'],
                "speed": result['stats']['tokens_per_second'],
            }
            
            # æ„å»ºMarkdownå†…å®¹
            md_content += f"## Preset: {preset_name}\n\n"
            md_content += f"**Description:** {preset_config['description']}\n\n"
            md_content += f"**Time:** {result['stats']['total_time']:.2f}s  \n"
            md_content += f"**Length:** {result['stats']['text_length']} characters  \n"
            md_content += f"**Speed:** {result['stats']['tokens_per_second']:.1f} tokens/s  \n\n"
            md_content += f"### Generated Text\n\n"
            md_content += f"```markdown\n{result['text']}\n```\n\n"
            md_content += "---\n\n"

            print(f"ç”¨æ—¶: {result['stats']['total_time']:.2f}ç§’")
            print(f"è¾“å‡ºé•¿åº¦: {result['stats']['text_length']}å­—ç¬¦")
            
            # æ¢å¤åŸå§‹é…ç½®
            self.config = original_config
        
        # æ‰“å°å¯¹æ¯”è¡¨
        print("\n" + "=" * 60)
        print("ğŸ“Š æ€§èƒ½å¯¹æ¯”æ±‡æ€»:")
        print("-" * 60)
        print(f"{'é…ç½®':<10} {'ç”¨æ—¶(ç§’)':<10} {'å­—ç¬¦æ•°':<10} {'é€Ÿåº¦(t/s)':<12}")
        print("-" * 60)
        
        for name, stats in results_for_table.items():
            print(f"{name:<10} {stats['time']:<10.2f} {stats['length']:<10} {stats['speed']:<12.1f}")
        
        # ä¿å­˜å¯¹æ¯”ç»“æœåˆ°Markdownæ–‡ä»¶
        output_file = output_dir / (Path(image_path).stem + "_comparison.md")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
        print(f"\nğŸ’¾ å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    def adaptive_process(self, image_path: str) -> str:
        """
        è‡ªé€‚åº”å¤„ç† - æ ¹æ®å›¾åƒå†…å®¹è‡ªåŠ¨é€‰æ‹©æœ€ä½³å‚æ•°
        
        Args:
            image_path: å›¾åƒè·¯å¾„
        
        Returns:
            è¯†åˆ«çš„æ–‡æœ¬
        """
        print("ğŸ¤– è‡ªé€‚åº”å¤„ç†æ¨¡å¼")
        
        # åˆ†æå›¾åƒç‰¹å¾
        image = Image.open(image_path)
        width, height = image.size
        aspect_ratio = width / height
        
        # æ ¹æ®å›¾åƒç‰¹å¾é€‰æ‹©é…ç½®
        if aspect_ratio > 1.5:
            # å®½å›¾åƒï¼Œå¯èƒ½æ˜¯è¡¨æ ¼
            print("   æ£€æµ‹åˆ°: å®½å¹…å›¾åƒï¼Œä½¿ç”¨è¡¨æ ¼ä¼˜åŒ–é…ç½®")
            preset = "table"
        elif height > 2000:
            # é•¿å›¾åƒï¼Œå¯èƒ½æ˜¯é•¿æ–‡æ¡£
            print("   æ£€æµ‹åˆ°: é•¿æ–‡æ¡£ï¼Œä½¿ç”¨é«˜è´¨é‡é…ç½®")
            preset = "quality"
        else:
            # æ ‡å‡†æ–‡æ¡£
            print("   æ£€æµ‹åˆ°: æ ‡å‡†æ–‡æ¡£ï¼Œä½¿ç”¨å¹³è¡¡é…ç½®")
            preset = "balanced"
        
        # åº”ç”¨é…ç½®
        self.config = self.PRESET_CONFIGS[preset]
        self.generation_config = GenerationConfig(**self.config.get("generation", {}))
        
        # å¤„ç†
        result = self.process_with_params(image_path)
        return result['text']

def demo_all_features():
    """æ¼”ç¤ºæ‰€æœ‰åŠŸèƒ½"""
    print("ğŸ© Nougat é«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # 1. åŸºç¡€ä½¿ç”¨
    print("\n1ï¸âƒ£ åŸºç¡€ä½¿ç”¨ç¤ºä¾‹:")
    print("-" * 40)
    ocr = NougatAdvancedOCR(preset="balanced")
    
    # 2. è‡ªå®šä¹‰å‚æ•°
    print("\n2ï¸âƒ£ è‡ªå®šä¹‰å‚æ•°ç¤ºä¾‹:")
    print("-" * 40)
    custom_config = {
        "model": "facebook/nougat-base",
        "generation": {
            "max_length": 4096,
            "num_beams": 7,
            "temperature": 0.8,
            "top_k": 40,
            "top_p": 0.95,
            "repetition_penalty": 1.1,
            "length_penalty": 0.65,
            "no_repeat_ngram_size": 4,
            "do_sample": False,
            "early_stopping": True
        }
    }
    ocr_custom = NougatAdvancedOCR(custom_config=custom_config)
    
    # 3. å‚æ•°ç»„åˆç¤ºä¾‹
    print("\n3ï¸âƒ£ å¸¸ç”¨å‚æ•°ç»„åˆ:")
    print("-" * 40)
    
    # å¿«é€Ÿè‰ç¨¿æ¨¡å¼
    print("å¿«é€Ÿè‰ç¨¿æ¨¡å¼:")
    print("  - num_beams=1 (è´ªå©ªè§£ç )")
    print("  - max_length=1024")
    print("  - early_stopping=True")
    
    # é«˜ç²¾åº¦æ¨¡å¼
    print("\né«˜ç²¾åº¦æ¨¡å¼:")
    print("  - num_beams=10")
    print("  - temperature=0.7")
    print("  - no_repeat_ngram_size=5")
    print("  - early_stopping=False")
    
    # åˆ›é€ æ€§æ¨¡å¼
    print("\nåˆ›é€ æ€§æ¨¡å¼ (ä¸æ¨èç”¨äºOCR):")
    print("  - do_sample=True")
    print("  - temperature=1.2")
    print("  - top_k=50")
    print("  - top_p=0.9")

if __name__ == "__main__":
    import argparse
    import glob
    
    parser = argparse.ArgumentParser(description='Nougat é«˜çº§å‚æ•°æ¼”ç¤º')
    parser.add_argument('image', nargs='?', help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--preset', choices=['fast', 'balanced', 'quality', 'math', 'table'],
                       default='balanced', help='ä½¿ç”¨é¢„è®¾é…ç½®')
    parser.add_argument('--compare', action='store_true', help='æ¯”è¾ƒæ‰€æœ‰é…ç½®')
    parser.add_argument('--adaptive', action='store_true', help='è‡ªé€‚åº”æ¨¡å¼')
    parser.add_argument('--demo', action='store_true', help='æ¼”ç¤ºæ¨¡å¼')
    parser.add_argument('--batch', help='æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡')
    
    # ç”Ÿæˆå‚æ•°
    parser.add_argument('--max-length', type=int, help='æœ€å¤§è¾“å‡ºé•¿åº¦')
    parser.add_argument('--num-beams', type=int, help='Beamæœç´¢æ•°é‡')
    parser.add_argument('--temperature', type=float, help='æ¸©åº¦å‚æ•°')
    parser.add_argument('--top-k', type=int, help='Top-Ké‡‡æ ·')
    parser.add_argument('--top-p', type=float, help='Top-Pé‡‡æ ·')
    parser.add_argument('--repetition-penalty', type=float, help='é‡å¤æƒ©ç½š')
    parser.add_argument('--length-penalty', type=float, help='é•¿åº¦æƒ©ç½š')
    parser.add_argument('--no-repeat-ngram-size', type=int, help='ç¦æ­¢é‡å¤n-gram')
    parser.add_argument('--do-sample', action='store_true', help='ä½¿ç”¨é‡‡æ ·')
    parser.add_argument('--no-early-stopping', action='store_true', help='ç¦ç”¨æ—©åœ')
    
    args = parser.parse_args()
    
    if args.demo:
        demo_all_features()
    elif args.batch:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        image_files = sorted(glob.glob(f"{args.batch}/*.jpg") + glob.glob(f"{args.batch}/*.png") + 
                            glob.glob(f"{args.batch}/*.jpeg") + glob.glob(f"{args.batch}/*.JPG"))
        
        if not image_files:
            print(f"é”™è¯¯: åœ¨ {args.batch} ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            exit(1)
            
        print(f"ğŸ” æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        print(f"ğŸ“‚ æ‰¹é‡å¤„ç†ç›®å½•: {args.batch}")
        print("=" * 60)
        
        # åˆ›å»ºå¤„ç†å™¨
        ocr = NougatAdvancedOCR(preset=args.preset)
        
        # å¤„ç†æ¯ä¸ªå›¾ç‰‡
        for idx, img_path in enumerate(image_files, 1):
            if args.compare:
                # æ¯”è¾ƒæ¨¡å¼
                ocr.compare_configs(img_path, total_images=len(image_files), current_index=idx)
            elif args.adaptive:
                # è‡ªé€‚åº”æ¨¡å¼
                print(f"\nğŸ”„ è¿›åº¦: [{idx}/{len(image_files)}] - {(idx/len(image_files))*100:.1f}%")
                print(f"ğŸ“„ å½“å‰å¤„ç†: {Path(img_path).name}")
                text = ocr.adaptive_process(img_path)
                print("\nè¯†åˆ«ç»“æœ:")
                print(text)
            else:
                # å¸¸è§„å¤„ç†
                print(f"\nğŸ”„ è¿›åº¦: [{idx}/{len(image_files)}] - {(idx/len(image_files))*100:.1f}%")
                print(f"ğŸ“„ å½“å‰å¤„ç†: {Path(img_path).name}")
                result = ocr.process_with_params(
                    img_path,
                    max_length=args.max_length,
                    num_beams=args.num_beams,
                    temperature=args.temperature,
                    top_k=args.top_k,
                    top_p=args.top_p,
                    repetition_penalty=args.repetition_penalty,
                    length_penalty=args.length_penalty,
                    no_repeat_ngram_size=args.no_repeat_ngram_size,
                    do_sample=args.do_sample,
                    early_stopping=not args.no_early_stopping if args.no_early_stopping else None
                )
                
                print("\nğŸ“ è¯†åˆ«ç»“æœ:")
                print("=" * 60)
                print(result['text'])
    elif args.image:
        # åˆ›å»ºå¤„ç†å™¨
        ocr = NougatAdvancedOCR(preset=args.preset)
        
        if args.compare:
            # æ¯”è¾ƒæ¨¡å¼
            ocr.compare_configs(args.image)
        elif args.adaptive:
            # è‡ªé€‚åº”æ¨¡å¼
            text = ocr.adaptive_process(args.image)
            print("\nè¯†åˆ«ç»“æœ:")
            print(text)
        else:
            # å¸¸è§„å¤„ç†
            result = ocr.process_with_params(
                args.image,
                max_length=args.max_length,
                num_beams=args.num_beams,
                temperature=args.temperature,
                top_k=args.top_k,
                top_p=args.top_p,
                repetition_penalty=args.repetition_penalty,
                length_penalty=args.length_penalty,
                no_repeat_ngram_size=args.no_repeat_ngram_size,
                do_sample=args.do_sample,
                early_stopping=not args.no_early_stopping if args.no_early_stopping else None
            )
            
            print("\nğŸ“ è¯†åˆ«ç»“æœ:")
            print("=" * 60)
            print(result['text'])
    else:
        print("è¯·æä¾›å›¾åƒè·¯å¾„æˆ–ä½¿ç”¨ --demo æŸ¥çœ‹æ¼”ç¤º")
        parser.print_help()
