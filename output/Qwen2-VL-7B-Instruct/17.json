{
  "image": "data/pdf_ocr_samples/17.jpg",
  "model_id": "Qwen/Qwen2-VL-7B-Instruct",
  "results": [
    {
      "preset": "concise_default",
      "prompt": "You are an expert science figure and chart captioner. Write a concise, accurate caption describing what the figure shows, axes, units, and the main trend.",
      "generation_kwargs": {
        "max_new_tokens": 384,
        "do_sample": false,
        "num_beams": 3,
        "repetition_penalty": 1.05,
        "no_repeat_ngram_size": 3
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe figure is a table that compares the performance of different models before and after perturbation. The models are listed in the first column, with \"ALL\" and \"SEQ\" representing different evaluation metrics. The table shows the percentage of correct predictions for each model, with the \"Before Perturb\" column showing the performance before perturbation and the \"After Perturb | ALL\" and \"| V P\" columns showing the percentage change in performance. The main trend is that perturbation generally decreases the performance, with some models showing a larger decrease than others."
    },
    {
      "preset": "long_detailed",
      "prompt": "Analyze the figure carefully and write a detailed caption. Include key entities, labels/values, and trends. Avoid hallucination; describe only what is visible.",
      "generation_kwargs": {
        "max_new_tokens": 768,
        "do_sample": false,
        "num_beams": 3,
        "repetition_penalty": 1.07,
        "no_repeat_ngram_size": 3
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe image is a table comparing the performance of different models before and after perturbation. The table is divided into two main sections: \"Before Perturb\" and \"After Perturb.\" Each section is further divided into columns labeled \"ALL,\" \"SEQ,\" \"ALL_d,\" \"V P,\" and \"VP.\" The rows represent different studies or models, including \"Herzig et al. (2020),\" \"Eisenschlos et al., 2019,\" \"Liu et al, 21,\" \"TAPASBASE,\" \"TABLEFORMERBASE,\" and so on. The values in the table range from 61.1 to 74.5, indicating some form of score or metric. The perturbation percentages are shown in the \"VP\" column, with values ranging from 0.1% to 15.1%."
    },
    {
      "preset": "strict_beam",
      "prompt": "Provide a precise caption focusing on axes, units, and relationships. Be factual and terse.",
      "generation_kwargs": {
        "max_new_tokens": 512,
        "do_sample": false,
        "num_beams": 5,
        "repetition_penalty": 1.1,
        "no_repeat_ngram_size": 4
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe table shows the results of different models before and after perturbation. The models include TapasBase, TableFormerBase, TapasLarge, TableFormerLarge, TapasBase inter, and TableFormerLarge inter. The results are presented in terms of accuracy, with values ranging from 61.1 to 72.4."
    },
    {
      "preset": "creative_sample",
      "prompt": "Describe the chart with clarity. Mention axes, units, labels, and any visible trends.",
      "generation_kwargs": {
        "max_new_tokens": 512,
        "do_sample": true,
        "temperature": 0.6,
        "top_p": 0.9,
        "num_beams": 1,
        "repetition_penalty": 1.02,
        "no_repeat_ngram_size": 3
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe provided figure is a table that compares the performance of different models before and after perturbation. The table is divided into two main sections: \"Before Perturb\" and \"After Perturb.\" Each section contains multiple rows, each representing a different model or model variant.\n\n### Axes and Units:\n- **X-axis:** Not explicitly labeled, but it represents different models or model variants.\n- **Y-axis:** Represents the performance metrics, which are percentages.\n\n### Labels:\n- The table has two main columns: \"ALL\" and a sub-column \"SEQ.\"\n- There are additional columns for \"ALL_d,\" \"ALL,\" \"VP,\" and \"V P.\"\n\n### Visible Trends:\n1. **Performance Metrics:**\n   - The \"ALL SEQ\" column shows the performance before perturbation, with values ranging from 31.3% to 74.5%.\n   - After perturbation (in the \"ALL VP\" column), the performance generally decreases, with some exceptions.\n   For example, \"Herzig et al. (2020)\" shows a decrease from 67.2% to approximately 57.4%, while \"TABLEFORMER_LARGE inter\" shows an increase from 70.6% to around 72.3%.\n\n2. **Model Variants:**\n    - The table includes both base and large variants of models like TAPAS and TABLEFORMER.\n    - \"inter\" indicates a specific variant or configuration of the models.\n\n3. **Perturbation Impact:**\n  - The perturbation generally reduces the performance across all models, with the exception of \"TABLE FORMER_LARGE\" which shows a slight increase in performance after perturbations.\n\n### Detailed Analysis:\n- For \"Herzog et al.\" (2nd row), the base model shows a performance of 61.1% before perturb, which drops to 56.7% after perturbing.\n- \"Eisenschlos et al\" (3rd row) shows a similar trend, with a drop from 59.7 to 46.1.\n- The \"Liu et al (21)\" model variant shows a significant drop from around 60% to less than 50%.\n- For the \"TABLE FOMER\" models, the base variant shows an initial performance of around 58.7%, which drops slightly to 66.6%, while the large variant shows improvements from 44.8%"
    }
  ],
  "presets_run": [
    "concise_default",
    "long_detailed",
    "strict_beam",
    "creative_sample"
  ]
}