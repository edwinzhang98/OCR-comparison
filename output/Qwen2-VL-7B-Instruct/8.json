{
  "image": "data/pdf_ocr_samples/8.jpg",
  "model_id": "Qwen/Qwen2-VL-7B-Instruct",
  "results": [
    {
      "preset": "concise_default",
      "prompt": "You are an expert science figure and chart captioner. Write a concise, accurate caption describing what the figure shows, axes, units, and the main trend.",
      "generation_kwargs": {
        "max_new_tokens": 384,
        "do_sample": false,
        "num_beams": 3,
        "repetition_penalty": 1.05,
        "no_repeat_ngram_size": 3
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe figure shows a table comparing the performance of different models on two datasets, dev and test. The models include TapasBase, TableFormerBase, TapasLarge, and TableFormerLarge, with and without inter-sqa. The performance is measured in terms of accuracy, with higher values indicating better performance."
    },
    {
      "preset": "long_detailed",
      "prompt": "Analyze the figure carefully and write a detailed caption. Include key entities, labels/values, and trends. Avoid hallucination; describe only what is visible.",
      "generation_kwargs": {
        "max_new_tokens": 768,
        "do_sample": false,
        "num_beams": 3,
        "repetition_penalty": 1.07,
        "no_repeat_ngram_size": 3
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe image is a table comparing the performance of different models on two datasets: \"dev\" and \"test\". The models listed are \"Herzig et al. (2020)\", \"Eisenschlos et al.\", \"TAPASBASE\", \"TABLEFORMERBASE\", and their respective large versions. The performance metrics are given as percentages. For example, \"Her zig et al.\" has a dev score of 48.8 and a test score of around 51.5. The \"TAPA SBASE\" model has a lower dev score (23.6) but a higher test score (34.8) compared to its large version. The table also shows that adding \"inter-sqa\" to the model name generally increases the test score."
    },
    {
      "preset": "strict_beam",
      "prompt": "Provide a precise caption focusing on axes, units, and relationships. Be factual and terse.",
      "generation_kwargs": {
        "max_new_tokens": 512,
        "do_sample": false,
        "num_beams": 5,
        "repetition_penalty": 1.1,
        "no_repeat_ngram_size": 4
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe table shows the performance of different models on the dev and test sets. The models include TAPASBASE, TABLEFORMERBASE, TAPASLARGE, and TABLEFORMERLARGE. The performance is measured in terms of accuracy, with values ranging from 23.6 to 52.6."
    },
    {
      "preset": "creative_sample",
      "prompt": "Describe the chart with clarity. Mention axes, units, labels, and any visible trends.",
      "generation_kwargs": {
        "max_new_tokens": 512,
        "do_sample": true,
        "temperature": 0.6,
        "top_p": 0.9,
        "num_beams": 1,
        "repetition_penalty": 1.02,
        "no_repeat_ngram_size": 3
      },
      "output_text": "user\nDescribe the figure precisely.\nassistant\nThe figure is a table comparing the performance of different models on two datasets: dev and test. The models are listed in the first column, and their performance metrics are shown in the subsequent columns. The performance metrics include the average number of correct answers (dev) and the average percentage of correct responses (test).\n\n- The first row shows the performance for the models \"Herzig et al. (2020)\" and \"Eisenschlos et al (21)\", with the dev score being 48.8 and the test score being higher at 51.5.\n- The second row shows \"TAPASBASE\" and \"TABLEFORMERBASE\", with the TAPAS BASE model having a dev score of 23.6 and a test score of slightly higher at around 24.1.\n- Similarly, the third row shows TAPALARGE and TABLEFORMERLARGE, with TAPALS LARGE having a higher dev score (40.8) and a slightly higher test score (around 41.7).\n- The fourth row shows inter-sqa models, with the inter-sqA model for TAPABASE having a slightly lower dev score than the base model but a higher test performance. The same trend is observed for TABLEFORMERALARGE inter-sQA, with a higher performance on the test set.\n- Finally, the fifth row shows that the inter-SQA models for TAPA LARGE and TABLE FORMER LARGE have the highest performance, with both models achieving a dev and a higher percentage of test scores.\n\nOverall, the table shows that adding the inter-qa module improves the performance across all models, especially on the dev set, and that the TABLEFORMERM LARGE model performs the best overall."
    }
  ],
  "presets_run": [
    "concise_default",
    "long_detailed",
    "strict_beam",
    "creative_sample"
  ]
}