# Comparison for 2.jpg

## Preset: fast

**Description:** 快速模式 - 牺牲一些质量换取速度

**Time:** 0.69s  
**Length:** 0 characters  
**Speed:** 4.6 tokens/s  

### Generated Text

```markdown

```

---

## Preset: balanced

**Description:** 平衡模式 - 速度和质量的平衡

**Time:** 1.18s  
**Length:** 232 characters  
**Speed:** 55.6 tokens/s  

### Generated Text

```markdown


\begin{tabular}{c c c c}  & Transformer (Self Attention) & Learnable **structure enforced attention bias scalars**. We use 13 types of attention biases based on _task independent_ relation between header, row, column, text, etc.


```

---

## Preset: quality

**Description:** 高质量模式 - 最佳识别质量

**Time:** 9.63s  
**Length:** 234 characters  
**Speed:** 6.7 tokens/s  

### Generated Text

```markdown


\begin{tabular}{c c c c c}  & Transformer (Self Attention) & Learnable **structure enforced attention bias scalars**. We use 13 types of attention biases based on _task independent_ relation between header, row, column, text, etc.


```

---

## Preset: math

**Description:** 数学文档模式 - 优化数学公式识别

**Time:** 3.17s  
**Length:** 232 characters  
**Speed:** 20.2 tokens/s  

### Generated Text

```markdown


\begin{tabular}{c c c c}  & Transformer (Self Attention) & Learnable **structure enforced attention bias scalars**. We use 13 types of attention biases based on _task independent_ relation between header, row, column, text, etc.


```

---

## Preset: table

**Description:** 表格文档模式 - 优化表格识别

**Time:** 0.77s  
**Length:** 172 characters  
**Speed:** 82.6 tokens/s  

### Generated Text

```markdown


Learable **structure enforced attention bias scalars**. We use 13 types of attention biases based on _task independent_ relation between header, row, column, text, etc.


```

---

